---
title: "Analisi Macro-territoriale"
REVIEW: "AG"
Note reviewew: "
---
##############ESITO REVIEW#####
##### NESSUNA MODIFICA, HO SOLO CANCELLATO PARTE INUTILE (RIGA 55 IN POI)

########## INTRODUCTION ###########
```{r}
### functions
check.packages <- function(pkg){
  new.pkg <- pkg[!(pkg %in% installed.packages()[, "Package"])] 
  if (length(new.pkg)) 
    install.packages(new.pkg, dependencies = TRUE)
  sapply(pkg, require, character.only = TRUE)
}

readdata <- function(fn){
  dt_temp <- fread(fn, sep=",", header=T, encoding = 'UTF-8')
  return(dt_temp)
}

### functions
readdata_semi <- function(fn){
  dt_temp <- fread(fn, sep=";", header=T, encoding='UTF-8')
  return(dt_temp)
}

descriptives <- function(x) {
  if (is.numeric(x)) return(summary(x))
  if (is.character(x)) return(table(x))
}

substrRight <- function(x, n){
  substr(x, nchar(x)-n+1, nchar(x))
}

string.counter<-function(strings, pattern){  
  counts<-NULL 
  for(i in 1:length(strings)){
    counts[i]<-length(attr(gregexpr(pattern,strings[i])[[1]], "match.length")[attr(gregexpr(pattern,strings[i])[[1]], "match.length")>0])
  } 
  return(counts)
}

ListRequiredPackages<-c("data.table", "bit64" ,"lubridate", "dplyr", "readxl", "writexl", 
                        "mudata2", "gdata", "sjmisc", "DataExplorer",
                        "doParallel", "parallelMap", "parallel", "pdp", "pROC",
                        "caret", "tables", "expss", "rmarkdown")
check.packages(ListRequiredPackages)


library(readr)
library(tidyverse)
library(dplyr)
library("writexl")
library(janitor)
library("stringr")
```

####Definisco la mappa d'Italia, con le adiacenze tra comuni come matrice e come lista
```{r}
setwd("//archivio_bene/ARCHIVIO_GENERALE/Bene/Aree Tecniche/BIA/Dati_Esterni/ShapeFile_2023/Limiti01012023_g/Com01012023_g")
require(maptools)
require(shape)
require(spdep)
require(ape)

comune.poly<-readShapePoly("Com01012023_g_WGS84",IDvar="PRO_COM",verbose=TRUE)

comune.poly<-comune.poly[comune.poly@data$COMUNE!="Campione d'Italia" & comune.poly@data$COMUNE!="Capraia Isola"& comune.poly@data$COMUNE!="Isola del Giglio" & comune.poly@data$COMUNE!="Ponza" & comune.poly@data$COMUNE!="Ventotene" & comune.poly@data$COMUNE!="Procida" & comune.poly@data$COMUNE!="Isole Tremiti" & comune.poly@data$COMUNE!="Favignana"& comune.poly@data$COMUNE!="Pantelleria" & comune.poly@data$COMUNE!="Ustica" & comune.poly@data$COMUNE!="Lipari" & comune.poly@data$COMUNE!="Lampedusa e Linosa" & comune.poly@data$COMUNE!="La Maddalena" & comune.poly@data$COMUNE!="Carloforte",]
colSums(is.na(comune.poly@data))
comune.poly@data$COMUNE_A<-as.factor("a")
rif <-as.data.frame(comune.poly@data)

lista_comuni<-subset(rif, select = c(COMUNE, PRO_COM_T))
#write_xlsx(lista_comuni,"//archivio_bene/ARCHIVIO_GENERALE/Bene/Aree Tecniche/BIA/Analisi_Microterritoriale/Tesi_Programmi/Programmi/lista_comuni.xlsx")

class(comune.poly)
plot(comune.poly)
head(slot(comune.poly,"data"))
slotNames(comune.poly)
#centr=coordinates(comune.poly)
#struttura di vicinato
comune.nb<-poly2nb(comune.poly)
summary(comune.nb)
coords <- coordinates(comune.poly)
plot(comune.poly)
plot(comune.nb, coords, add=TRUE)

#matrice di adiacenza
comune.mat<-nb2mat(comune.nb,zero.policy=TRUE)
sum(is.na(comune.mat))
dim(comune.mat)
comune.list<-mat2listw(comune.mat)

```
```{r echo=FALSE}
library(tidyverse)
library(hrbrthemes)
library(viridis)
library(gridExtra)
library(ggrepel)
library(plotly)
library(wCorr)
```
Creo matrice comune.mat2 composta 0 ed 1
```{r}
comune.mat2<-comune.mat
comune.mat2[comune.mat2>0]<-1
rm(comune.mat)
```

Genero la matrice D (matrice distanze) partendo dalla matrice di adiacenza
Ricordiamoci che sono ordinate come lista_comuni
```{r}
library(igraph)
library(graphsim)
distance_matrix_abs <- make_distance_adjmat(comune.mat2, absolute = FALSE)

grafo <- graph_from_adjacency_matrix(
  comune.mat2,
  mode ="undirected",
  weighted = NULL,
  diag = TRUE,
  add.colnames = NULL,
  add.rownames = NA
)
length(V(grafo))
E<- edge(grafo)
D<- distances(
  grafo,
  v = V(grafo),
  to = V(grafo),
  mode = "all",
  weights = NULL,
  algorithm = "automatic"
)
histogram

distanze<-as.data.frame(D)

fwrite(distanze, "//archivio_bene/ARCHIVIO_GENERALE/Bene/Aree Tecniche/BIA/Analisi_Microterritoriale/Smoothing Dati Mercato/02_Export/matrice_delle_distanze1.r")
#aaa<-as.data.frame(colnames(distanze))
#write_xlsx(aaa,"//archivio_bene/ARCHIVIO_GENERALE/Bene/Aree Tecniche/BIA/Analisi_Microterritoriale/Tesi_Programmi/Programmi/vecchi_nomi.xlsx")

```

```{r}

Dati_di_mercato <- readdata("//archivio_bene/ARCHIVIO_GENERALE/Bene/Aree Tecniche/BIA/Analisi_Microterritoriale/Smoothing Dati Mercato/00_Dati/Comuni_2018_2021_v7.csv")
is_float(Dati_di_mercato$`Frequenza sinistri 2020`)

Dati_di_mercato$COMUNE=Dati_di_mercato$Comune_residenza
Dati_di_mercato2 <- Dati_di_mercato[!duplicated(Dati_di_mercato$COMUNE),]
db_completo<-dplyr::left_join (lista_comuni, Dati_di_mercato2, merge, by="COMUNE")
#manca il dedup!
trova <- db_completo[is.na(db_completo$`Frequenza sinistri 2021`),]
#eliminate le eccezioni!
```
PLotto le frequenze con stessa scala
```{r}
frequenza_comune=merge(comune.poly,db_completo,by.y="PRO_COM_T",by.x="PRO_COM_T",all.x=T,duplicateGeoms = TRUE)
breakpoints<-quantile(frequenza_comune@data$`Frequenza sinistri 2019`,na.rm=T,(0:8)/8)
cols<-c("darkblue", "blue", "light blue","green","yellow","orange","red","darkred")
plot(frequenza_comune,col=cols[findInterval(frequenza_comune@data$`Frequenza sinistri 2018`,vec=breakpoints,all.inside=F,rightmost.closed=T)],border=FALSE)
plot(frequenza_comune,col=cols[findInterval(frequenza_comune@data$`Frequenza sinistri 2019`,vec=breakpoints,all.inside=F,rightmost.closed=T)],border=FALSE)
plot(frequenza_comune,col=cols[findInterval(frequenza_comune@data$`Frequenza sinistri 2020`,vec=breakpoints,all.inside=F,rightmost.closed=T)],border=FALSE)
plot(frequenza_comune,col=cols[findInterval(frequenza_comune@data$`Frequenza sinistri 2021`,vec=breakpoints,all.inside=F,rightmost.closed=T)],border=FALSE)

```
PLotto le frequenze con scale diverse
```{r}
frequenza_comune=merge(comune.poly,db_completo,by.y="PRO_COM_T",by.x="PRO_COM_T",all.x=T,duplicateGeoms = TRUE)
cols<-c("darkblue", "blue", "light blue","green","yellow","orange","red","darkred")
breakpoints<-quantile(frequenza_comune@data$`Frequenza sinistri 2018`,na.rm=T,(0:8)/8)
plot(frequenza_comune,col=cols[findInterval(frequenza_comune@data$`Frequenza sinistri 2018`,vec=breakpoints,all.inside=F,rightmost.closed=T)],border=FALSE)
breakpoints<-quantile(frequenza_comune@data$`Frequenza sinistri 2019`,na.rm=T,(0:8)/8)
plot(frequenza_comune,col=cols[findInterval(frequenza_comune@data$`Frequenza sinistri 2019`,vec=breakpoints,all.inside=F,rightmost.closed=T)],border=FALSE)
breakpoints<-quantile(frequenza_comune@data$`Frequenza sinistri 2020`,na.rm=T,(0:8)/8)
plot(frequenza_comune,col=cols[findInterval(frequenza_comune@data$`Frequenza sinistri 2020`,vec=breakpoints,all.inside=F,rightmost.closed=T)],border=FALSE)
breakpoints<-quantile(frequenza_comune@data$`Frequenza sinistri 2021`,na.rm=T,(0:8)/8)
plot(frequenza_comune,col=cols[findInterval(frequenza_comune@data$`Frequenza sinistri 2021`,vec=breakpoints,all.inside=F,rightmost.closed=T)],border=FALSE)

```
Calcolo la media 2018-2020 per stimare la media 2021
```{r}
aggiungi_var <-frequenza_comune@data
aggiungi_var$frequenza_20182020 <- (aggiungi_var$`Frequenza sinistri 2018`*aggiungi_var$`Veicoli Anno 2018`+aggiungi_var$`Frequenza sinistri 2019`*aggiungi_var$`Veicoli Anno 2019`+aggiungi_var$`Frequenza sinistri 2020`*aggiungi_var$`Veicoli Anno 2020`)/pmax((aggiungi_var$`Veicoli Anno 2020`+aggiungi_var$`Veicoli Anno 2019`+aggiungi_var$`Veicoli Anno 2018`),0.001)
aggiungi_var$veicoli_20182020 <- (aggiungi_var$`Veicoli Anno 2020`+aggiungi_var$`Veicoli Anno 2019`+aggiungi_var$`Veicoli Anno 2018`)
frequenza_comune@data <- aggiungi_var
breakpoints<-quantile(frequenza_comune@data$`Frequenza sinistri 2021`,na.rm=T,(0:8)/8)
cols<-c("darkblue", "blue", "light blue","green","yellow","orange","red","darkred")
plot(frequenza_comune,col=cols[findInterval(frequenza_comune@data$frequenza_20182020,vec=breakpoints,all.inside=F,rightmost.closed=T)],border=FALSE)


```

SONO ARRIVATA QUI; TUTTP GIA' calibrato!!
Risultato migliore:
A=
0.03
n=20
media=0.05067689
errore=0.006469730

```{r}
#STEP 1: DEFINIRE parametro a (credibility parameter) e poi Zi (credibility_weight)
data_analisi <-frequenza_comune@data
A<-rep(0,26)
n<-rep(0,26)
media_random<-rep(0,26)
errore<-rep(0,26)
check_media_random<- data.frame(A,n,media_random,errore)
breakpoints<-quantile(frequenza_comune@data$`Frequenza sinistri 2021`,na.rm=T,(0:8)/8)
cols<-c("darkblue", "blue", "light blue","green","yellow","orange","red","darkred")
plot(frequenza_comune,col=cols[findInterval(frequenza_comune@data$`Frequenza sinistri 2021`,vec=breakpoints,all.inside=F,rightmost.closed=T)],border=FALSE)
title("FREQUENZA SINISTRI 2021")
legend("topright",legend=leglabs(round(breakpoints,3)),fill=cols,cex=0.6)
check_media_random[1,1]=0
check_media_random[1,2]=0
check_media_random[1,3]=sum(data_analisi$`Veicoli Anno 2021`*data_analisi$`Frequenza sinistri 2021`)/sum(data_analisi$`Veicoli Anno 2021`)
valori_A<-c(0.01,0.02,0.03,0.04,0.05)
valori_n<-c(18,19,20,21,22)
for (A in 1:5){
  for (n in 1:5){
credibility_parameter<-valori_A[A]*mean(data_analisi$veicoli_20182020)
Z1<-as.vector((data_analisi$veicoli_20182020)/(credibility_parameter+data_analisi$veicoli_20182020))

#STEP 2: DEFINIRE observed residual code i che sappiamo essere uguali a frequenza_2019
Observed_residual_code<-as.vector(data_analisi$frequenza_20182020)

#STEP3: DEFINIRE (1-Zi)* weighted avg residual of..
Z2<-1-Z1

#Eseguo rapporto tra cicli for per trovare Media_pesata_freq.

D_n<-1/D^valori_n[n]

for (i in 1:nrow(data_analisi)){
# for (i in 1:nrow(data_analisi)){
  D_n[i,i]=0
 }

V=as.matrix(data_analisi$frequenza_20182020*data_analisi$veicoli_20182020)
V2=as.vector(data_analisi$veicoli_20182020)

numeratore=D_n %*% V
denominatore=D_n%*% V2
#per chi non confina con niente con esposizione...
denominatore[denominatore==0]<-1
media_pesata_freq<-numeratore/denominatore

smoothed_residual_cod<-(Z1*Observed_residual_code+Z2*media_pesata_freq)
data_analisi$smoothed_frequenza_cod<-smoothed_residual_cod
data_analisi$errore_comune<-(data_analisi$smoothed_frequenza_cod-data_analisi$`Frequenza sinistri 2021`)^2*data_analisi$`Veicoli Anno 2021`

check_media_random[(A-1)*5+n+1,1]=valori_A[A]
check_media_random[(A-1)*5+n+1,2]=valori_n[n]
check_media_random[(A-1)*5+n+1,3]=sum(data_analisi$`Veicoli Anno 2021`*data_analisi$smoothed_frequenza_cod)/sum(data_analisi$`Veicoli Anno 2021`)
check_media_random[(A-1)*5+n+1,4]=sqrt(sum(data_analisi$errore_comune)/sum(data_analisi$`Veicoli Anno 2021`))

frequenza_comune@data<-data_analisi


#PLOTTO I GRAFICI E AGGIUNGO ALLA TAB IL VALORE DELLA FREQUENZA IN RELAZIONE AD "A" ED "n"
plot(frequenza_comune,col=cols[findInterval(frequenza_comune@data$smoothed_frequenza_cod,vec=breakpoints,all.inside=F,rightmost.closed=T)],border=FALSE)
title(paste("FREQUENZA STIMATA A =",valori_A[A], "; n =", valori_n[n], sep=" ",collapse=NULL))
legend("topright",legend=leglabs(round(breakpoints,3)),fill=cols,cex=0.6)

data_analisi<-frequenza_comune@data
data_analisi$smoothed_frequenza_cod<-smoothed_residual_cod

nuovo_nome<-paste("smoothed_freq_A",A, "n", n, sep="_",collapse=NULL)
names(data_analisi)[names(data_analisi) == 'smoothed_frequenza_cod'] <- nuovo_nome
frequenza_comune@data<-data_analisi
  }
}
```

Rifaccio la media su tutti gli anni includendo il 2021 e applico i parametri
A= 0.03
n= 20

```{r}
aggiungi_var <-frequenza_comune@data
aggiungi_var$frequenza_20182021 <- (aggiungi_var$`Frequenza sinistri 2018`*aggiungi_var$`Veicoli Anno 2018`+aggiungi_var$`Frequenza sinistri 2019`*aggiungi_var$`Veicoli Anno 2019`+aggiungi_var$`Frequenza sinistri 2020`*aggiungi_var$`Veicoli Anno 2020`++aggiungi_var$`Frequenza sinistri 2021`*aggiungi_var$`Veicoli Anno 2021`)/pmax((aggiungi_var$`Veicoli Anno 2021`+aggiungi_var$`Veicoli Anno 2020`+aggiungi_var$`Veicoli Anno 2019`+aggiungi_var$`Veicoli Anno 2018`),0.001)
aggiungi_var$veicoli_20182021 <- (aggiungi_var$`Veicoli Anno 2021`+aggiungi_var$`Veicoli Anno 2020`+aggiungi_var$`Veicoli Anno 2019`+aggiungi_var$`Veicoli Anno 2018`)
frequenza_comune@data <- aggiungi_var
breakpoints<-quantile(frequenza_comune@data$`Frequenza sinistri 2021`,na.rm=T,(0:8)/8)
cols<-c("darkblue", "blue", "light blue","green","yellow","orange","red","darkred")
plot(frequenza_comune,col=cols[findInterval(frequenza_comune@data$frequenza_20182021,vec=breakpoints,all.inside=F,rightmost.closed=T)],border=FALSE)


```

```{r}
#STEP 1: DEFINIRE parametro a (credibility parameter) e poi Zi (credibility_weight)
data_analisi <-frequenza_comune@data
A<-0.03
n<-20

check_media_random<- data.frame(A,n,media_random,errore)
breakpoints<-quantile(frequenza_comune@data$frequenza_20182021, na.rm=T,(0:8)/8)
cols<-c("darkblue", "blue", "light blue","green","yellow","orange","red","darkred")
plot(frequenza_comune,col=cols[findInterval(frequenza_comune@data$frequenza_20182021,vec=breakpoints,all.inside=F,rightmost.closed=T)],border=FALSE)
title("FREQUENZA SINISTRI mercato 2018-2021")
legend("topright",legend=leglabs(round(breakpoints,3)),fill=cols,cex=0.6)
valori_A<-A
valori_n<-n

credibility_parameter<-valori_A*mean(data_analisi$veicoli_20182021)
Z1<-as.vector((data_analisi$veicoli_20182021)/(credibility_parameter+data_analisi$veicoli_20182021))

#STEP 2: DEFINIRE observed residual code i che sappiamo essere uguali a frequenza_2019
Observed_residual_code<-as.vector(data_analisi$frequenza_20182021)

#STEP3: DEFINIRE (1-Zi)* weighted avg residual of..
Z2<-1-Z1

#Eseguo rapporto tra cicli for per trovare Media_pesata_freq.

D_n<-1/D^valori_n

for (i in 1:nrow(data_analisi)){
# for (i in 1:nrow(data_analisi)){
  D_n[i,i]=0
 }

V=as.matrix(data_analisi$frequenza_20182021*data_analisi$veicoli_20182021)
V2=as.vector(data_analisi$veicoli_20182021)

numeratore=D_n %*% V
denominatore=D_n%*% V2
#per chi non confina con niente con esposizione...
denominatore[denominatore==0]<-1
media_pesata_freq<-numeratore/denominatore

smoothed_residual_cod<-(Z1*Observed_residual_code+Z2*media_pesata_freq)
data_analisi$smoothed_frequenza_cod<-smoothed_residual_cod
data_analisi$errore_comune<-(data_analisi$smoothed_frequenza_cod-data_analisi$frequenza_20182021)^2*data_analisi$veicoli_20182021

check_media_random[1,1]=valori_A
check_media_random[1,2]=valori_n
check_media_random[1,3]=sum(data_analisi$`Veicoli Anno 2021`*data_analisi$smoothed_frequenza_cod)/sum(data_analisi$veicoli_20182021)
check_media_random[1,4]=sqrt(sum(data_analisi$errore_comune)/sum(data_analisi$veicoli_20182021))

frequenza_comune@data<-data_analisi


#PLOTTO I GRAFICI E AGGIUNGO ALLA TAB IL VALORE DELLA FREQUENZA IN RELAZIONE AD "A" ED "n"
plot(frequenza_comune,col=cols[findInterval(frequenza_comune@data$smoothed_frequenza_cod,vec=breakpoints,all.inside=F,rightmost.closed=T)],border=FALSE)
title(paste("FREQUENZA STIMATA A =",valori_A, "; n =", valori_n, sep=" ",collapse=NULL))
legend("topright",legend=leglabs(round(breakpoints,3)),fill=cols,cex=0.6)

data_analisi<-frequenza_comune@data
data_analisi$smoothed_frequenza_cod<-smoothed_residual_cod

nuovo_nome<-"smoothed_freq_tot_1821"
names(data_analisi)[names(data_analisi) == 'smoothed_frequenza_cod'] <- nuovo_nome
frequenza_comune@data<-data_analisi

```
```{r}
data_analisi
write_xlsx(data_analisi,"//archivio_bene/ARCHIVIO_GENERALE/Bene/Aree Tecniche/BIA/Analisi_Microterritoriale/Smoothing Dati Mercato/02_Export/lista_comuni.xlsx")
```
Attenzione: sulle isole e spazi isolati devo ricordami di mettere l'osservato
"Campione d'Italia" 
"Capraia Isola"
"Isola del Giglio" 
"Ponza"
"Ventotene" 
"Procida"
"Isole Tremiti"
"Favignana
"Pantelleria" 
"Ustica"
"Lipari" 
"Lampedusa e Linosa" 
"La Maddalena"
"Carloforte"

```{r}
isole <- Dati_di_mercato[Dati_di_mercato$COMUNE=="Campione d'Italia"|Dati_di_mercato$COMUNE=="Capraia Isola"
                         |Dati_di_mercato$COMUNE=="Isola del Giglio"|Dati_di_mercato$COMUNE=="Ponza"|
                           Dati_di_mercato$COMUNE=="Ventotene"|Dati_di_mercato$COMUNE=="Procida"
                         |Dati_di_mercato$COMUNE=="Isole Tremiti"|Dati_di_mercato$COMUNE=="Favignana"
                         |Dati_di_mercato$COMUNE=="Pantelleria"|Dati_di_mercato$COMUNE=="Ustica"
                          |Dati_di_mercato$COMUNE=="Lipari"|Dati_di_mercato$COMUNE=="Lampedusa e Linosa"
                         |Dati_di_mercato$COMUNE=="La Maddalena"|Dati_di_mercato$COMUNE=="Carloforte"]
isole$frequenza_20182021 <- (isole$`Frequenza sinistri 2018`*isole$`Veicoli Anno 2018`+isole$`Frequenza sinistri 2019`*isole$`Veicoli Anno 2019`+isole$`Frequenza sinistri 2020`*isole$`Veicoli Anno 2020`+isole$`Frequenza sinistri 2021`*isole$`Veicoli Anno 2021`)/pmax((isole$`Veicoli Anno 2021`+isole$`Veicoli Anno 2020`+isole$`Veicoli Anno 2019`+isole$`Veicoli Anno 2018`),0.001)
setwd("//archivio_bene/ARCHIVIO_GENERALE/Bene/Aree Tecniche/BIA/Dati_Esterni/ShapeFile_2023/Limiti01012023_g/Com01012023_g")

comune.poly<-readShapePoly("Com01012023_g_WGS84",IDvar="PRO_COM",verbose=TRUE)


comune.poly@data$COMUNE_A<-as.factor("a")
rif <-as.data.frame(comune.poly@data)

lista_comuni<-subset(rif, select = c(COMUNE, PRO_COM_T))


isole2<-dplyr::inner_join (lista_comuni, isole, merge, by="COMUNE")
isole_mappa=merge(comune.poly,isole2,by.y="PRO_COM_T",by.x="PRO_COM_T",all.x=F,duplicateGeoms = TRUE)
isole3<-isole_mappa@data
isole4 <- subset (isole3, select=c(PRO_COM,ComuneCercaOLD,Comune_residenza,frequenza_20182021))
write_xlsx(isole4,"//archivio_bene/ARCHIVIO_GENERALE/Bene/Aree Tecniche/BIA/Analisi_Microterritoriale/Smoothing Dati Mercato/02_Export/lista_isole.xlsx")

```